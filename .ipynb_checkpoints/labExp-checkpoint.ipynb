{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Face Recognition via Sparse Representation\n",
    "\n",
    "## K-SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "\n",
    "img_path = \"./YaleB/\"\n",
    "# n_components: å­—å…¸æ‰€å«åŸå­ä¸ªæ•°ï¼ˆå­—å…¸çš„åˆ—æ•°ï¼‰\n",
    "n_components = 38 - 1\n",
    "'''\n",
    "è¿è¡ŒK-SVDç®—æ³•ï¼š \n",
    " å­—å…¸ğ·å¤§å°ï¼š64 Ã— 441 \n",
    " ç¨€ç–åº¦ï¼šğ‘† = 10 \n",
    " ç¨€ç–ç¼–ç ç®—æ³•ï¼šOMP \n",
    "'''\n",
    "\n",
    "select_train_num = 11000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KSVD(object):\n",
    "    def __init__(self,\n",
    "                 n_components=441,\n",
    "                 max_iter=30,\n",
    "                 tol=1e-6,\n",
    "                 n_nonzero_coefs=None):\n",
    "        \"\"\"\n",
    "        ç¨€ç–æ¨¡å‹Y = DXï¼ŒYä¸ºæ ·æœ¬çŸ©é˜µï¼Œä½¿ç”¨KSVDåŠ¨æ€æ›´æ–°å­—å…¸çŸ©é˜µDå’Œç¨€ç–çŸ©é˜µX\n",
    "        :param n_components: å­—å…¸æ‰€å«åŸå­ä¸ªæ•°ï¼ˆå­—å…¸çš„åˆ—æ•°ï¼‰\n",
    "        :param max_iter: æœ€å¤§è¿­ä»£æ¬¡æ•°\n",
    "        :param tol: ç¨€ç–è¡¨ç¤ºç»“æœçš„å®¹å·®\n",
    "        :param n_nonzero_coefs: ç¨€ç–åº¦\n",
    "        \"\"\"\n",
    "        self.sparsecode = None\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.n_components = n_components\n",
    "        self.n_nonzero_coefs = n_nonzero_coefs\n",
    "\n",
    "    def _initialize(self, y):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–å­—å…¸çŸ©é˜µ\n",
    "        \"\"\"\n",
    "        # u, s, v = self._svd(y)\n",
    "        # print(\"[_initialize]->u,s,v: \", u.shape, s.shape, v.shape)\n",
    "        # self.dictionary = u[:, :self.n_components]\n",
    "        self.dictionary = np.random.rand(8 * 8, self.n_components)\n",
    "\n",
    "    def _update_dict(self, y, d, x):\n",
    "        \"\"\"\n",
    "        ä½¿ç”¨KSVDæ›´æ–°å­—å…¸çš„è¿‡ç¨‹\n",
    "        \"\"\"\n",
    "        for i in range(self.n_components):\n",
    "            # np.nonzero å¾—åˆ°çŸ©é˜µé0å…ƒç´ ä½ç½®\n",
    "            index = np.nonzero(x[i, :])[0]\n",
    "            if len(index) == 0:\n",
    "                continue\n",
    "            # å°†ç¬¬iåˆ—æ¸…ç©º\n",
    "            d[:, i] = 0\n",
    "            # E := Y - D X = Y - Î£(lâ‰ j) d_l X\n",
    "            r = (y - np.dot(d, x))[:, index]\n",
    "            # çŸ©é˜µçš„ å¥‡å¼‚å€¼ åˆ†è§£\n",
    "            u, s, v = np.linalg.svd(r, full_matrices=False)\n",
    "            d[:, i] = u[:, 0].T\n",
    "            x[i, index] = s[0] * v[0, :]\n",
    "        return d, x\n",
    "\n",
    "    def _svd(self, a):\n",
    "        '''\n",
    "        ASK: X = US(V.T)\n",
    "        https://www.cnblogs.com/endlesscoding/p/10058532.html\n",
    "        '''\n",
    "        # --- ç‰¹å¾å€¼åˆ†è§£\n",
    "        # 1.æ•°æ®å¿…éœ€å…ˆè½¬ä¸ºæµ®ç‚¹å‹ï¼Œå¦åˆ™åœ¨è®¡ç®—çš„è¿‡ç¨‹ä¸­ä¼šæº¢å‡ºï¼Œå¯¼è‡´ç»“æœä¸å‡†ç¡®\n",
    "        a = a / 255.0\n",
    "        # 2.è®¡ç®—ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡\n",
    "        s, u = np.linalg.eigh(a.dot(a.T))\n",
    "        # --- è®¡ç®—å³å¥‡å¼‚çŸ©é˜µ\n",
    "        # 1.é™åºæ’åˆ—åï¼Œé€†åºè¾“å‡º\n",
    "        idx = np.argsort(s)[::-1]\n",
    "        # 2.å°†ç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡ä¹Ÿå¯¹åº”æ’å¥½åº\n",
    "        s = np.sort(s)[::-1]\n",
    "        u = u[:, idx]\n",
    "        # 3.è®¡ç®—å¥‡å¼‚å€¼çŸ©é˜µçš„é€†\n",
    "        s = np.sqrt(s)\n",
    "        s_inv = np.linalg.inv(np.diag(s))\n",
    "        # 4.è®¡ç®—å³å¥‡å¼‚çŸ©é˜µ\n",
    "        v = s_inv.dot((u.T).dot(a))\n",
    "        # åˆ†åˆ«ä¸ºå·¦å¥‡å¼‚çŸ©é˜µï¼Œæ‰€æœ‰å¥‡å¼‚å€¼ï¼Œå³å¥‡å¼‚çŸ©é˜µã€‚\n",
    "        return u, s, v\n",
    "\n",
    "    def omp(self, B, y, eps=.1, max_iter=90):\n",
    "        \"\"\"\n",
    "        https://blog.csdn.net/theonegis/article/details/78230737\n",
    "        \"\"\"\n",
    "        r = y\n",
    "        sparse_idx = []\n",
    "        sparse_min_w = None\n",
    "        i = 0\n",
    "        while True:\n",
    "            i += 1\n",
    "            # è®¡ç®—å„ä¸ªåŸå­å¯¹yçš„è´¡çŒ®å€¼ï¼Œå¹¶é€‰æ‹©ç»å¯¹å€¼æœ€å¤§çš„\n",
    "            max_r_idx = np.argmax(np.abs(np.dot(r, B)))\n",
    "            sparse_idx.append(max_r_idx)\n",
    "            # ä¼°è®¡çº¿æ€§æ¨¡å‹ä¸­çš„ç³»æ•°ï¼ša=np.linalg.lstsq(x,b),æœ‰b=a*x\n",
    "            sparse_min_w = np.linalg.lstsq(B[:, sparse_idx], y, rcond=None)[0]\n",
    "            # æ›´æ–°æ®‹å·®r_t=y âˆ’ A_t x^t\n",
    "            r = y - np.dot(B[:, sparse_idx], sparse_min_w)\n",
    "            err = np.linalg.norm(r, ord=2)\n",
    "            # print('[omp]->iter: {}, ->err={}'.format(i, err))\n",
    "            if err < eps or i >= max_iter:\n",
    "                break\n",
    "        print(\"[omp]->times: \", i, \",->err: \", np.linalg.norm(r, ord=2))\n",
    "        min_w = np.zeros(B.shape[1], dtype=np.float32)\n",
    "        for idx, val in enumerate(sparse_idx):\n",
    "            min_w[val] += sparse_min_w[idx]\n",
    "        # min_w[sparse_idx] = sparse_min_w\n",
    "        return min_w\n",
    "\n",
    "    def comp_omp(self, B, y):\n",
    "        # x_j = self.omp(self.dictionary, y[:, j])\n",
    "        r = y\n",
    "        sparse_idx = []\n",
    "        sparse_min_w = None\n",
    "\n",
    "        # è®¡ç®—å„ä¸ªåŸå­å¯¹yçš„è´¡çŒ®å€¼ï¼Œå¹¶é€‰æ‹©ç»å¯¹å€¼æœ€å¤§çš„\n",
    "        max_r_idx = np.argmax(np.abs(np.dot(r, B)))\n",
    "        sparse_idx.append(max_r_idx)\n",
    "        # ä¼°è®¡çº¿æ€§æ¨¡å‹ä¸­çš„ç³»æ•°ï¼ša=np.linalg.lstsq(x,b),æœ‰b=a*x\n",
    "        sparse_min_w = np.linalg.lstsq(B[:, sparse_idx], y, rcond=None)[0]\n",
    "        # æ›´æ–°æ®‹å·®r_t=y âˆ’ A_t x^t\n",
    "        r = y - np.dot(B[:, sparse_idx], sparse_min_w)\n",
    "\n",
    "        # err = np.linalg.norm(r, ord=2)\n",
    "        # print(\"[omp]->i: \", i, \",->err: \", np.linalg.norm(r, ord=2))\n",
    "        # print('è¯¯å·®', np.linalg.norm(r, ord=2))\n",
    "\n",
    "        min_w = np.zeros(B.shape[1], dtype=np.float32)\n",
    "        # è¿”å› enumerate(æšä¸¾) å¯¹è±¡\n",
    "        for idx, val in enumerate(sparse_idx):\n",
    "            min_w[val] += sparse_min_w[idx]\n",
    "\n",
    "        return min_w\n",
    "\n",
    "    def iter_omp(self, B, y):\n",
    "        '''\n",
    "        å°† y æ‹†è§£æŒ‰æ¯åˆ—æ›´æ–°\n",
    "        '''\n",
    "        global select_train_num\n",
    "        x = np.zeros((self.n_components, select_train_num))\n",
    "        if (y.ndim == 2):\n",
    "            for j in range(y.shape[1]):\n",
    "                # min_w[sparse_idx] = sparse_min_w\n",
    "                x[:, j] = self.comp_omp(B, y[:, j])\n",
    "            return x\n",
    "        else:\n",
    "            return self.comp_omp(B, y)\n",
    "\n",
    "    def run2(self, y):\n",
    "        '''\n",
    "        omp ç®—æ³•2ï¼Œæ¯æ¬¡è¿­ä»£ï¼Œæœ€åæ›´æ–°å­—å…¸\n",
    "        '''\n",
    "        self._initialize(y)\n",
    "\n",
    "        global select_train_num\n",
    "        x = np.zeros((self.n_components, select_train_num))\n",
    "        for j in range(y.shape[1]):\n",
    "            print(\"->iter: \", j, end=' ')\n",
    "            x_j = self.omp(self.dictionary, y[:, j], eps=0.001)\n",
    "            x[:, j] = x_j\n",
    "\n",
    "        # æ±‚èŒƒæ•°\n",
    "        e = np.linalg.norm(y - np.dot(self.dictionary, x))\n",
    "        self._update_dict(y, self.dictionary, x)\n",
    "        # æœ€åä¸€æ¬¡ompè¿”å›ç»“æœ\n",
    "        self.sparsecode = np.zeros((self.n_components, select_train_num))\n",
    "        for j in range(y.shape[1]):\n",
    "            x_j = self.omp(self.dictionary, y[:, j])\n",
    "            self.sparsecode[:, j] = x_j\n",
    "        return self.dictionary, self.sparsecode\n",
    "\n",
    "    def run(self, y):\n",
    "        self._initialize(y)\n",
    "        for i in range(self.max_iter):\n",
    "            # ompç®—æ³•--1 sklearn çš„ompç®—æ³•åŒ…ï¼Œç”¨ä»¥å¯¹æ¯”åˆ†æ\n",
    "            x = linear_model.orthogonal_mp(\n",
    "                self.dictionary, y, n_nonzero_coefs=self.n_nonzero_coefs)\n",
    "\n",
    "            # ompç®—æ³•--3\n",
    "            # x = self.iter_omp(self.dictionary, y)\n",
    "\n",
    "            # æ±‚èŒƒæ•°\n",
    "            e = np.linalg.norm(y - np.dot(self.dictionary, x))\n",
    "            print(\"[run]->i: \", i, \", ->e: \", e)\n",
    "            if e < self.tol:\n",
    "                break\n",
    "            self._update_dict(y, self.dictionary, x)\n",
    "        self.sparsecode = linear_model.orthogonal_mp(\n",
    "            self.dictionary, y, n_nonzero_coefs=self.n_nonzero_coefs)\n",
    "        # self.sparsecode = self.iter_omp(self.dictionary, y)\n",
    "        return self.dictionary, self.sparsecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Divide:\n",
    "    def __init__(self, b_w, b_h):\n",
    "        '''\n",
    "        b_w: block width\n",
    "        b_h: block height\n",
    "        '''\n",
    "        self.block_width = b_w\n",
    "        self.block_height = b_h\n",
    "\n",
    "    def encode(self, mat):\n",
    "        (W, H) = mat.shape\n",
    "        # (192, 168)->(24,21)\n",
    "        w_len = int(W / self.block_width)\n",
    "        h_len = int(H / self.block_height)\n",
    "        res = np.zeros((self.block_width * self.block_height, w_len * h_len))\n",
    "        for i in range(h_len):\n",
    "            for j in range(w_len):\n",
    "                temp = mat[j * self.block_width:(j + 1) * self.block_width,\n",
    "                           i * self.block_height:(i + 1) * self.block_height]\n",
    "                temp = temp.reshape(self.block_width * self.block_height)\n",
    "                res[:, i * w_len + j] = temp\n",
    "        return res\n",
    "\n",
    "    def decode(self, mat, W, H):\n",
    "        '''\n",
    "        mat.shape should be ( block_width*block_height, ~ = 24*21 )\n",
    "        '''\n",
    "        w_len = int(W / self.block_width)\n",
    "        h_len = int(H / self.block_height)\n",
    "        mat = mat.reshape(self.block_width * self.block_height, w_len * h_len)\n",
    "        \n",
    "        res = np.zeros((W, H))\n",
    "        for i in range(h_len):\n",
    "            for j in range(w_len):\n",
    "                temp = mat[:, i * w_len + j]\n",
    "                temp = temp.reshape(self.block_width, self.block_height)\n",
    "                res[j * self.block_width:(j + 1) * self.block_width,\n",
    "                    i * self.block_height:(i + 1) * self.block_height] = temp\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img():\n",
    "    '''\n",
    "    äººè„¸æ•°æ®é›†ä¸­é€‰å–çš„11000ä¸ª8 Ã— 8çš„å›¾åƒ å—ï¼ˆå„ä¸ªéƒ¨ä½ï¼‰\n",
    "    æ¯ä¸€ä¸ª8 Ã— 8çš„å›¾åƒå—ï¼Œæ˜¯64 Ã— 11000çš„çŸ©é˜µğ‘Œä¸­çš„ä¸€åˆ—\n",
    "    '''\n",
    "    src_img_w = 192\n",
    "    src_img_h = 168\n",
    "\n",
    "    # dataset = np.zeros((38,192,168), np.float)\n",
    "    dataset = np.zeros((src_img_w * src_img_h, 38), np.float)\n",
    "    cnt_num = 0\n",
    "    img_list = sorted(os.listdir(img_path))\n",
    "    os.chdir(img_path)\n",
    "    for img in img_list:\n",
    "        if img.endswith(\".pgm\"):\n",
    "            # print(img.size)\n",
    "            gray_img = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
    "            # åˆ†å—æå– 8*8 çš„ block æ±‡æˆçŸ©é˜µ\n",
    "            # gray_img.reshape(src_img_w * src_img_h, 1)\n",
    "            divide = Divide(b_w=8, b_h=8)\n",
    "            gray_img = divide.encode(gray_img)\n",
    "            # gray_img = cv2.resize(gray_img, (src_img_w, src_img_h),interpolation=cv2.INTER_AREA)\n",
    "            dataset[:, cnt_num] = gray_img.reshape(src_img_w * src_img_h, )\n",
    "            cnt_num += 1\n",
    "    train_data = dataset.reshape(8 * 8, 24 * 21 * 38)\n",
    "    idx = random.sample(list(range(24 * 21 * (38 - 1))), select_train_num)\n",
    "    train_data = train_data[:, idx]\n",
    "    return train_data, dataset[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_result(B, eva_B):\n",
    "    '''\n",
    "    è¯¯å·®è®¡ç®—: \n",
    "    error_rate = sqrt(||B - ~B||_2_F / 64)\n",
    "    '''\n",
    "    return (np.linalg.norm(B - eva_B))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # å®éªŒå›¾åƒï¼šä¸€å¼ äººè„¸å›¾åƒï¼Œç”±594ä¸ªå—ç»„æˆçš„ï¼ˆä¸åœ¨11000 ä¸ªè®­ ç»ƒæ•°æ®é›†ä¸­ï¼‰\n",
    "    # 1.å¯¹äºæ¯ä¸ª8 Ã— 8çš„å›¾åƒå—ğµï¼š2.åœ¨éšæœºä½ç½®ï¼Œéšæœºåˆ é™¤ä¸€éƒ¨åˆ†åƒç´ \n",
    "    train_data, test_data = read_img()\n",
    "    # æŒ‰å—å¤„ç†\n",
    "    divide = Divide(b_w=8, b_h=8)\n",
    "    missed_img = copy.deepcopy(test_data)\n",
    "    missed_img = missed_img.reshape(8 * 8, 21 * 24)\n",
    "    for j in range(21 * 24):\n",
    "        # missed_img[:, j][random.randint(0, 64 - 1)] = 0\n",
    "        missed_img[:, j][random.sample(list(range(0, 64)), 10)] = 0\n",
    "    plt.subplot(1, 2, 1), plt.imshow(divide.decode(test_data, 192, 168))\n",
    "    plt.subplot(1, 2, 2), plt.imshow(divide.decode(missed_img, 192, 168))\n",
    "    plt.show()\n",
    "    cv2.imwrite('test_data.png',divide.decode(test_data.reshape(8 * 8, 24 * 21), 192, 168))\n",
    "    cv2.imwrite('missed_img.png', divide.decode(missed_img, 192, 168))\n",
    "\n",
    "    print(\"[train_data]: \", train_data.shape, \"[test_data]: \", test_data.shape)\n",
    "\n",
    "    # show the dictionary\n",
    "    # plt.imshow(divide.decode(train_data, 110 * 8, 100 * 8)),plt.show()\n",
    "\n",
    "    # 3.åˆ†åˆ«åŸºäºå­¦ä¹ åˆ°çš„K-SVDå­—å…¸ã€ç›´æ¥æ„å»ºçš„Haarå­—å…¸ã€ DCTå­—å…¸ï¼Œä½¿ç”¨OMPç®—æ³•ï¼Œè·å¾—å—æŸå›¾åƒçš„ç¨€ç–è¡¨è¾¾\n",
    "    k_svd = KSVD()\n",
    "    # run(): iter_omp / sklearn , run2(): omp\n",
    "    # dictionary, sparsecode = k_svd.run(train_data)\n",
    "    dictionary, sparsecode = k_svd.run2(train_data)\n",
    "\n",
    "    plt.subplot(1, 2, 1), plt.imshow(divide.decode(train_data, 110 * 8, 100 * 8))\n",
    "    plt.subplot(1, 2, 2), plt.imshow(divide.decode(dictionary, 21 * 8, 21 * 8))\n",
    "    plt.show()\n",
    "\n",
    "    # 4.å—ğµçš„ç³»æ•°çŸ©é˜µè¡¨ç¤ºä¸ºğ‘‹_ğµ\n",
    "    test_data = test_data.reshape(8 * 8, 21 * 24)\n",
    "    # å¯¹äºç¼ºå¤±éƒ¨åˆ†è¿›è¡Œå‰”é™¤ TODOï¼šå›¾åƒåŸæœ¬å°±æœ‰0å€¼æ€ä¹ˆåŠ\n",
    "    x = np.zeros((441, 21 * 24))\n",
    "    for j in range(21 * 24):\n",
    "        idx = []\n",
    "        for i in range(missed_img.shape[0]):\n",
    "            if missed_img[i, j] == 0:\n",
    "                idx.append(i)\n",
    "        # print(len(idx), end=' ')\n",
    "        y = copy.deepcopy(missed_img[:, j])\n",
    "        B = copy.deepcopy(dictionary)\n",
    "        y = np.delete(y, idx)\n",
    "        B = np.delete(B, idx, axis=0)\n",
    "        # print(y.shape, B.shape, end=' ')\n",
    "        # ä¸‰ç§ä¸åŒçš„ompç­–ç•¥\n",
    "        # x_j = linear_model.orthogonal_mp(B, y, n_nonzero_coefs=None)\n",
    "        print(\"->iter: \", j, end=' ')\n",
    "        x_j = k_svd.omp(B, y, eps=.1)\n",
    "        # x_j = k_svd.iter_omp(B, y)\n",
    "        x[:, j] = x_j\n",
    "\n",
    "    print(\"[x with missed_img]->shape: \", x.shape)\n",
    "    # 5.é‡æ„çš„å— ~ğµ = ğ· ğ‘‹_ğµ\n",
    "    # 6.é‡æ„è¯¯å·®ï¼š\n",
    "    result = dictionary.dot(x)\n",
    "    print(\"[test_result]: \", test_result(test_data, result))\n",
    "    print(\"[missed_img]: \", test_result(missed_img, result))\n",
    "    # cv2.imwrite('result.png', divide.decode(result, 192, 168))\n",
    "\n",
    "    # show the image\n",
    "    plt.subplot(1, 3, 1), plt.imshow(divide.decode(test_data, 192, 168))\n",
    "    plt.subplot(1, 3, 2), plt.imshow(divide.decode(missed_img, 192, 168))\n",
    "    plt.subplot(1, 3, 3), plt.imshow(divide.decode(result, 192, 168))\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
