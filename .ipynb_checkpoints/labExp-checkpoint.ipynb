{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Face Recognition via Sparse Representation\n",
    "\n",
    "## K-SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "\n",
    "img_path = \"./YaleB/\"\n",
    "# n_components: 字典所含原子个数（字典的列数）\n",
    "n_components = 38 - 1\n",
    "'''\n",
    "运行K-SVD算法： \n",
    " 字典𝐷大小：64 × 441 \n",
    " 稀疏度：𝑆 = 10 \n",
    " 稀疏编码算法：OMP \n",
    "'''\n",
    "\n",
    "select_train_num = 11000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KSVD(object):\n",
    "    def __init__(self,\n",
    "                 n_components=441,\n",
    "                 max_iter=30,\n",
    "                 tol=1e-6,\n",
    "                 n_nonzero_coefs=None):\n",
    "        \"\"\"\n",
    "        稀疏模型Y = DX，Y为样本矩阵，使用KSVD动态更新字典矩阵D和稀疏矩阵X\n",
    "        :param n_components: 字典所含原子个数（字典的列数）\n",
    "        :param max_iter: 最大迭代次数\n",
    "        :param tol: 稀疏表示结果的容差\n",
    "        :param n_nonzero_coefs: 稀疏度\n",
    "        \"\"\"\n",
    "        self.sparsecode = None\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.n_components = n_components\n",
    "        self.n_nonzero_coefs = n_nonzero_coefs\n",
    "\n",
    "    def _initialize(self, y):\n",
    "        \"\"\"\n",
    "        初始化字典矩阵\n",
    "        \"\"\"\n",
    "        # u, s, v = self._svd(y)\n",
    "        # print(\"[_initialize]->u,s,v: \", u.shape, s.shape, v.shape)\n",
    "        # self.dictionary = u[:, :self.n_components]\n",
    "        self.dictionary = np.random.rand(8 * 8, self.n_components)\n",
    "\n",
    "    def _update_dict(self, y, d, x):\n",
    "        \"\"\"\n",
    "        使用KSVD更新字典的过程\n",
    "        \"\"\"\n",
    "        for i in range(self.n_components):\n",
    "            # np.nonzero 得到矩阵非0元素位置\n",
    "            index = np.nonzero(x[i, :])[0]\n",
    "            if len(index) == 0:\n",
    "                continue\n",
    "            # 将第i列清空\n",
    "            d[:, i] = 0\n",
    "            # E := Y - D X = Y - Σ(l≠j) d_l X\n",
    "            r = (y - np.dot(d, x))[:, index]\n",
    "            # 矩阵的 奇异值 分解\n",
    "            u, s, v = np.linalg.svd(r, full_matrices=False)\n",
    "            d[:, i] = u[:, 0].T\n",
    "            x[i, index] = s[0] * v[0, :]\n",
    "        return d, x\n",
    "\n",
    "    def _svd(self, a):\n",
    "        '''\n",
    "        ASK: X = US(V.T)\n",
    "        https://www.cnblogs.com/endlesscoding/p/10058532.html\n",
    "        '''\n",
    "        # --- 特征值分解\n",
    "        # 1.数据必需先转为浮点型，否则在计算的过程中会溢出，导致结果不准确\n",
    "        a = a / 255.0\n",
    "        # 2.计算特征值和特征向量\n",
    "        s, u = np.linalg.eigh(a.dot(a.T))\n",
    "        # --- 计算右奇异矩阵\n",
    "        # 1.降序排列后，逆序输出\n",
    "        idx = np.argsort(s)[::-1]\n",
    "        # 2.将特征值对应的特征向量也对应排好序\n",
    "        s = np.sort(s)[::-1]\n",
    "        u = u[:, idx]\n",
    "        # 3.计算奇异值矩阵的逆\n",
    "        s = np.sqrt(s)\n",
    "        s_inv = np.linalg.inv(np.diag(s))\n",
    "        # 4.计算右奇异矩阵\n",
    "        v = s_inv.dot((u.T).dot(a))\n",
    "        # 分别为左奇异矩阵，所有奇异值，右奇异矩阵。\n",
    "        return u, s, v\n",
    "\n",
    "    def omp(self, B, y, eps=.1, max_iter=90):\n",
    "        \"\"\"\n",
    "        https://blog.csdn.net/theonegis/article/details/78230737\n",
    "        \"\"\"\n",
    "        r = y\n",
    "        sparse_idx = []\n",
    "        sparse_min_w = None\n",
    "        i = 0\n",
    "        while True:\n",
    "            i += 1\n",
    "            # 计算各个原子对y的贡献值，并选择绝对值最大的\n",
    "            max_r_idx = np.argmax(np.abs(np.dot(r, B)))\n",
    "            sparse_idx.append(max_r_idx)\n",
    "            # 估计线性模型中的系数：a=np.linalg.lstsq(x,b),有b=a*x\n",
    "            sparse_min_w = np.linalg.lstsq(B[:, sparse_idx], y, rcond=None)[0]\n",
    "            # 更新残差r_t=y − A_t x^t\n",
    "            r = y - np.dot(B[:, sparse_idx], sparse_min_w)\n",
    "            err = np.linalg.norm(r, ord=2)\n",
    "            # print('[omp]->iter: {}, ->err={}'.format(i, err))\n",
    "            if err < eps or i >= max_iter:\n",
    "                break\n",
    "        print(\"[omp]->times: \", i, \",->err: \", np.linalg.norm(r, ord=2))\n",
    "        min_w = np.zeros(B.shape[1], dtype=np.float32)\n",
    "        for idx, val in enumerate(sparse_idx):\n",
    "            min_w[val] += sparse_min_w[idx]\n",
    "        # min_w[sparse_idx] = sparse_min_w\n",
    "        return min_w\n",
    "\n",
    "    def comp_omp(self, B, y):\n",
    "        # x_j = self.omp(self.dictionary, y[:, j])\n",
    "        r = y\n",
    "        sparse_idx = []\n",
    "        sparse_min_w = None\n",
    "\n",
    "        # 计算各个原子对y的贡献值，并选择绝对值最大的\n",
    "        max_r_idx = np.argmax(np.abs(np.dot(r, B)))\n",
    "        sparse_idx.append(max_r_idx)\n",
    "        # 估计线性模型中的系数：a=np.linalg.lstsq(x,b),有b=a*x\n",
    "        sparse_min_w = np.linalg.lstsq(B[:, sparse_idx], y, rcond=None)[0]\n",
    "        # 更新残差r_t=y − A_t x^t\n",
    "        r = y - np.dot(B[:, sparse_idx], sparse_min_w)\n",
    "\n",
    "        # err = np.linalg.norm(r, ord=2)\n",
    "        # print(\"[omp]->i: \", i, \",->err: \", np.linalg.norm(r, ord=2))\n",
    "        # print('误差', np.linalg.norm(r, ord=2))\n",
    "\n",
    "        min_w = np.zeros(B.shape[1], dtype=np.float32)\n",
    "        # 返回 enumerate(枚举) 对象\n",
    "        for idx, val in enumerate(sparse_idx):\n",
    "            min_w[val] += sparse_min_w[idx]\n",
    "\n",
    "        return min_w\n",
    "\n",
    "    def iter_omp(self, B, y):\n",
    "        '''\n",
    "        将 y 拆解按每列更新\n",
    "        '''\n",
    "        global select_train_num\n",
    "        x = np.zeros((self.n_components, select_train_num))\n",
    "        if (y.ndim == 2):\n",
    "            for j in range(y.shape[1]):\n",
    "                # min_w[sparse_idx] = sparse_min_w\n",
    "                x[:, j] = self.comp_omp(B, y[:, j])\n",
    "            return x\n",
    "        else:\n",
    "            return self.comp_omp(B, y)\n",
    "\n",
    "    def run2(self, y):\n",
    "        '''\n",
    "        omp 算法2，每次迭代，最后更新字典\n",
    "        '''\n",
    "        self._initialize(y)\n",
    "\n",
    "        global select_train_num\n",
    "        x = np.zeros((self.n_components, select_train_num))\n",
    "        for j in range(y.shape[1]):\n",
    "            print(\"->iter: \", j, end=' ')\n",
    "            x_j = self.omp(self.dictionary, y[:, j], eps=0.001)\n",
    "            x[:, j] = x_j\n",
    "\n",
    "        # 求范数\n",
    "        e = np.linalg.norm(y - np.dot(self.dictionary, x))\n",
    "        self._update_dict(y, self.dictionary, x)\n",
    "        # 最后一次omp返回结果\n",
    "        self.sparsecode = np.zeros((self.n_components, select_train_num))\n",
    "        for j in range(y.shape[1]):\n",
    "            x_j = self.omp(self.dictionary, y[:, j])\n",
    "            self.sparsecode[:, j] = x_j\n",
    "        return self.dictionary, self.sparsecode\n",
    "\n",
    "    def run(self, y):\n",
    "        self._initialize(y)\n",
    "        for i in range(self.max_iter):\n",
    "            # omp算法--1 sklearn 的omp算法包，用以对比分析\n",
    "            x = linear_model.orthogonal_mp(\n",
    "                self.dictionary, y, n_nonzero_coefs=self.n_nonzero_coefs)\n",
    "\n",
    "            # omp算法--3\n",
    "            # x = self.iter_omp(self.dictionary, y)\n",
    "\n",
    "            # 求范数\n",
    "            e = np.linalg.norm(y - np.dot(self.dictionary, x))\n",
    "            print(\"[run]->i: \", i, \", ->e: \", e)\n",
    "            if e < self.tol:\n",
    "                break\n",
    "            self._update_dict(y, self.dictionary, x)\n",
    "        self.sparsecode = linear_model.orthogonal_mp(\n",
    "            self.dictionary, y, n_nonzero_coefs=self.n_nonzero_coefs)\n",
    "        # self.sparsecode = self.iter_omp(self.dictionary, y)\n",
    "        return self.dictionary, self.sparsecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Divide:\n",
    "    def __init__(self, b_w, b_h):\n",
    "        '''\n",
    "        b_w: block width\n",
    "        b_h: block height\n",
    "        '''\n",
    "        self.block_width = b_w\n",
    "        self.block_height = b_h\n",
    "\n",
    "    def encode(self, mat):\n",
    "        (W, H) = mat.shape\n",
    "        # (192, 168)->(24,21)\n",
    "        w_len = int(W / self.block_width)\n",
    "        h_len = int(H / self.block_height)\n",
    "        res = np.zeros((self.block_width * self.block_height, w_len * h_len))\n",
    "        for i in range(h_len):\n",
    "            for j in range(w_len):\n",
    "                temp = mat[j * self.block_width:(j + 1) * self.block_width,\n",
    "                           i * self.block_height:(i + 1) * self.block_height]\n",
    "                temp = temp.reshape(self.block_width * self.block_height)\n",
    "                res[:, i * w_len + j] = temp\n",
    "        return res\n",
    "\n",
    "    def decode(self, mat, W, H):\n",
    "        '''\n",
    "        mat.shape should be ( block_width*block_height, ~ = 24*21 )\n",
    "        '''\n",
    "        w_len = int(W / self.block_width)\n",
    "        h_len = int(H / self.block_height)\n",
    "        mat = mat.reshape(self.block_width * self.block_height, w_len * h_len)\n",
    "        \n",
    "        res = np.zeros((W, H))\n",
    "        for i in range(h_len):\n",
    "            for j in range(w_len):\n",
    "                temp = mat[:, i * w_len + j]\n",
    "                temp = temp.reshape(self.block_width, self.block_height)\n",
    "                res[j * self.block_width:(j + 1) * self.block_width,\n",
    "                    i * self.block_height:(i + 1) * self.block_height] = temp\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img():\n",
    "    '''\n",
    "    人脸数据集中选取的11000个8 × 8的图像 块（各个部位）\n",
    "    每一个8 × 8的图像块，是64 × 11000的矩阵𝑌中的一列\n",
    "    '''\n",
    "    src_img_w = 192\n",
    "    src_img_h = 168\n",
    "\n",
    "    # dataset = np.zeros((38,192,168), np.float)\n",
    "    dataset = np.zeros((src_img_w * src_img_h, 38), np.float)\n",
    "    cnt_num = 0\n",
    "    img_list = sorted(os.listdir(img_path))\n",
    "    os.chdir(img_path)\n",
    "    for img in img_list:\n",
    "        if img.endswith(\".pgm\"):\n",
    "            # print(img.size)\n",
    "            gray_img = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
    "            # 分块提取 8*8 的 block 汇成矩阵\n",
    "            # gray_img.reshape(src_img_w * src_img_h, 1)\n",
    "            divide = Divide(b_w=8, b_h=8)\n",
    "            gray_img = divide.encode(gray_img)\n",
    "            # gray_img = cv2.resize(gray_img, (src_img_w, src_img_h),interpolation=cv2.INTER_AREA)\n",
    "            dataset[:, cnt_num] = gray_img.reshape(src_img_w * src_img_h, )\n",
    "            cnt_num += 1\n",
    "    train_data = dataset.reshape(8 * 8, 24 * 21 * 38)\n",
    "    idx = random.sample(list(range(24 * 21 * (38 - 1))), select_train_num)\n",
    "    train_data = train_data[:, idx]\n",
    "    return train_data, dataset[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_result(B, eva_B):\n",
    "    '''\n",
    "    误差计算: \n",
    "    error_rate = sqrt(||B - ~B||_2_F / 64)\n",
    "    '''\n",
    "    return (np.linalg.norm(B - eva_B))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 实验图像：一张人脸图像，由594个块组成的（不在11000 个训 练数据集中）\n",
    "    # 1.对于每个8 × 8的图像块𝐵：2.在随机位置，随机删除一部分像素\n",
    "    train_data, test_data = read_img()\n",
    "    # 按块处理\n",
    "    divide = Divide(b_w=8, b_h=8)\n",
    "    missed_img = copy.deepcopy(test_data)\n",
    "    missed_img = missed_img.reshape(8 * 8, 21 * 24)\n",
    "    for j in range(21 * 24):\n",
    "        # missed_img[:, j][random.randint(0, 64 - 1)] = 0\n",
    "        missed_img[:, j][random.sample(list(range(0, 64)), 10)] = 0\n",
    "    plt.subplot(1, 2, 1), plt.imshow(divide.decode(test_data, 192, 168))\n",
    "    plt.subplot(1, 2, 2), plt.imshow(divide.decode(missed_img, 192, 168))\n",
    "    plt.show()\n",
    "    cv2.imwrite('test_data.png',divide.decode(test_data.reshape(8 * 8, 24 * 21), 192, 168))\n",
    "    cv2.imwrite('missed_img.png', divide.decode(missed_img, 192, 168))\n",
    "\n",
    "    print(\"[train_data]: \", train_data.shape, \"[test_data]: \", test_data.shape)\n",
    "\n",
    "    # show the dictionary\n",
    "    # plt.imshow(divide.decode(train_data, 110 * 8, 100 * 8)),plt.show()\n",
    "\n",
    "    # 3.分别基于学习到的K-SVD字典、直接构建的Haar字典、 DCT字典，使用OMP算法，获得受损图像的稀疏表达\n",
    "    k_svd = KSVD()\n",
    "    # run(): iter_omp / sklearn , run2(): omp\n",
    "    # dictionary, sparsecode = k_svd.run(train_data)\n",
    "    dictionary, sparsecode = k_svd.run2(train_data)\n",
    "\n",
    "    plt.subplot(1, 2, 1), plt.imshow(divide.decode(train_data, 110 * 8, 100 * 8))\n",
    "    plt.subplot(1, 2, 2), plt.imshow(divide.decode(dictionary, 21 * 8, 21 * 8))\n",
    "    plt.show()\n",
    "\n",
    "    # 4.块𝐵的系数矩阵表示为𝑋_𝐵\n",
    "    test_data = test_data.reshape(8 * 8, 21 * 24)\n",
    "    # 对于缺失部分进行剔除 TODO：图像原本就有0值怎么办\n",
    "    x = np.zeros((441, 21 * 24))\n",
    "    for j in range(21 * 24):\n",
    "        idx = []\n",
    "        for i in range(missed_img.shape[0]):\n",
    "            if missed_img[i, j] == 0:\n",
    "                idx.append(i)\n",
    "        # print(len(idx), end=' ')\n",
    "        y = copy.deepcopy(missed_img[:, j])\n",
    "        B = copy.deepcopy(dictionary)\n",
    "        y = np.delete(y, idx)\n",
    "        B = np.delete(B, idx, axis=0)\n",
    "        # print(y.shape, B.shape, end=' ')\n",
    "        # 三种不同的omp策略\n",
    "        # x_j = linear_model.orthogonal_mp(B, y, n_nonzero_coefs=None)\n",
    "        print(\"->iter: \", j, end=' ')\n",
    "        x_j = k_svd.omp(B, y, eps=.1)\n",
    "        # x_j = k_svd.iter_omp(B, y)\n",
    "        x[:, j] = x_j\n",
    "\n",
    "    print(\"[x with missed_img]->shape: \", x.shape)\n",
    "    # 5.重构的块 ~𝐵 = 𝐷 𝑋_𝐵\n",
    "    # 6.重构误差：\n",
    "    result = dictionary.dot(x)\n",
    "    print(\"[test_result]: \", test_result(test_data, result))\n",
    "    print(\"[missed_img]: \", test_result(missed_img, result))\n",
    "    # cv2.imwrite('result.png', divide.decode(result, 192, 168))\n",
    "\n",
    "    # show the image\n",
    "    plt.subplot(1, 3, 1), plt.imshow(divide.decode(test_data, 192, 168))\n",
    "    plt.subplot(1, 3, 2), plt.imshow(divide.decode(missed_img, 192, 168))\n",
    "    plt.subplot(1, 3, 3), plt.imshow(divide.decode(result, 192, 168))\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
